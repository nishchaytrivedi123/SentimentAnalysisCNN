{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5jxGjrKDJ0m",
        "colab_type": "code",
        "outputId": "34dff443-7b01-4641-f860-28209fbccf15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "import nltk \n",
        "import random \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords') \n",
        "nltk.download('wordnet') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQfU9LLeDQjJ",
        "colab_type": "code",
        "outputId": "6129199f-9bce-4b98-c4fa-bd952a70ffd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Imported the necessary libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/train.tsv\",delimiter='\\t',encoding='utf-8')\n",
        "df.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_QssFc89O3m",
        "colab_type": "code",
        "outputId": "91e7bbec-d10f-4ece-c89e-e8812c7bc263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "unique, counts = np.unique(df['Sentiment'], return_counts=True)\n",
        "\n",
        "plt.bar(unique, counts, 1)\n",
        "\n",
        "plt.title('Class Frequency')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('class_dist.jpg')\n",
        "plt.show()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEcCAYAAAD+73KmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYigFjYiIGOr/AZGAq4i7DhoDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrIXohCZD03Q",
        "colab_type": "code",
        "outputId": "b261884f-877d-4781-ff3f-4a0d2ebeb23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset = df.sample(frac=1).reset_index(drop=True)\n",
        "dataset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99516</td>\n",
              "      <td>5218</td>\n",
              "      <td>dysfunctionally</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111952</td>\n",
              "      <td>5942</td>\n",
              "      <td>essentially ruined -- or , rather</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>122259</td>\n",
              "      <td>6553</td>\n",
              "      <td>connect and express</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14969</td>\n",
              "      <td>643</td>\n",
              "      <td>cold movie</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55848</td>\n",
              "      <td>2792</td>\n",
              "      <td>controlling his crew</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                             Phrase  Sentiment\n",
              "0     99516        5218                    dysfunctionally          2\n",
              "1    111952        5942  essentially ruined -- or , rather          1\n",
              "2    122259        6553                connect and express          2\n",
              "3     14969         643                         cold movie          1\n",
              "4     55848        2792               controlling his crew          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdaEnYHgD2Eh",
        "colab_type": "code",
        "outputId": "8bd3aa1d-e2ed-4d6e-e82f-e54b4b968ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset ['Phrase'], dataset ['Sentiment'], test_size=0.3, random_state=2003)\n",
        "documents=[]\n",
        "\n",
        "X_train = np.array(X_train.values.tolist())\n",
        "Y_train = np.array(Y_train.values.tolist())\n",
        "\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  documents.append([list(word_tokenize(X_train[i])), Y_train[i]]) \n",
        "\n",
        "X_test = np.array(X_test.values.tolist())\n",
        "Y_test = np.array(Y_test.values.tolist())\n",
        "for i in range(len(X_test)):\n",
        "  documents.append([list(word_tokenize(X_test[i])), Y_test[i]]) \n",
        "\n",
        "documents[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A', 'comedy-drama', 'of', 'nearly', 'epic', 'proportions'], 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayc1oDMWD99o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer \n",
        "porter = PorterStemmer() \n",
        "lancaster=LancasterStemmer() \n",
        "wordnet_lemmatizer = WordNetLemmatizer() \n",
        "stopwords_en = stopwords.words(\"english\") \n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome \n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = False\n",
        "removePuncs = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4gzs2cpEB2L",
        "colab_type": "code",
        "outputId": "d76fa2b4-e3ca-46b3-ca46-5d7938fea29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for l in range(len(documents)):                   #For each review document \n",
        "  label = documents[l][1]                         #Save review label \n",
        "  tmpReview = []                                  #Placeholder list for new review \n",
        "  for w in documents[l][0]:                       #For each word this is review \n",
        "    newWord = w                                   #Set newWork to be the updated word \n",
        "    if remove_stopwords and (w in stopwords_en):  #if the word is a stopword & we want to remove stopwords \n",
        "      continue                                    #skip the word and don’t had it to the normalized review \n",
        "    if removePuncs and (w in punctuations):       #if the word is a punc. & we want to remove punctuations \n",
        "      continue                                    #skip the word and don’t had it to the normalized review \n",
        "    if useStemming:\n",
        "      #if useStemming is set to True \n",
        "      #Keep one stemmer commented out \n",
        "      #newWord = porter.stem(newWord) #User porter stemmer \n",
        "      newWord = lancaster.stem(newWord) #Use Lancaster stemmer \n",
        "    if useLemma: \n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord) \n",
        "    tmpReview.append(newWord)                     #Add normalized word to the tmp review \n",
        "  documents[l] = (tmpReview, label)             #Update the reviews list with clean review \n",
        "  documents[l] = (' '.join(tmpReview), label) \n",
        "\n",
        "print(documents[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('A comedy-drama nearly epic proportions', 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7TEahEEDFx",
        "colab_type": "code",
        "outputId": "08dd5543-f548-4311-a5db-0a4c072fe8fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "data = pd.DataFrame(documents, columns=['text', 'sentiment']) \n",
        "data.head(20)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A comedy-drama nearly epic proportions</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>action-packed experience ringside seat tough-m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Performances around tops two leads delivering ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>generalities</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'ll rewarded fine acting</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>crawl \\*\\*\\* embarrassment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>old-fashioned</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>one lucky</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>places world devastated war famine poverty doc...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>` inside</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>dry dry</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>kiddie</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>crush</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>used tool rally anti-Catholic protestors</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>felt Craven A Nightmare Elm Street ` The Hills...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>unexpected fizzability</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>contrived overblown tie-in ready</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>technical proficiency</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>many conflicts</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>outgag</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  sentiment\n",
              "0              A comedy-drama nearly epic proportions          3\n",
              "1   action-packed experience ringside seat tough-m...          3\n",
              "2   Performances around tops two leads delivering ...          3\n",
              "3                                        generalities          2\n",
              "4                            'll rewarded fine acting          4\n",
              "5                          crawl \\*\\*\\* embarrassment          1\n",
              "6                                       old-fashioned          1\n",
              "7                                           one lucky          2\n",
              "8   places world devastated war famine poverty doc...          2\n",
              "9                                            ` inside          2\n",
              "10                                            dry dry          2\n",
              "11                                             kiddie          2\n",
              "12                                              crush          1\n",
              "13           used tool rally anti-Catholic protestors          2\n",
              "14  felt Craven A Nightmare Elm Street ` The Hills...          1\n",
              "15                             unexpected fizzability          2\n",
              "16                   contrived overblown tie-in ready          0\n",
              "17                              technical proficiency          3\n",
              "18                                     many conflicts          1\n",
              "19                                             outgag          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9OtVctjEFgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(data['text'],  data['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY2GbK4yEMvy",
        "colab_type": "code",
        "outputId": "046797cc-b7a2-4754-e804-285ad4f37cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2000,ngram_range=(2, 2)) \n",
        "X = vectorizer.fit_transform(data[\"text\"]) \n",
        "Y = data['sentiment'] \n",
        " \n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhruvWtTEf7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f9CLqaGEe7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKPrQr61EQvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Converts the datasets to numpy arrays to work with our PyTorch model \n",
        "# X_train = np.array(X_train)\n",
        "# X_train = X_train.toarray() \n",
        "# Y_train = np.array(Y_train)\n",
        "\n",
        "# # Convert the testing data \n",
        "# X_test = X_test.toarray() \n",
        "# Y_test = np.array(Y_test)\n",
        "# print(x_train_np.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G3jKeNzE1Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjLFybl4Egr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_classes = 5\n",
        "epochs = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms-h9PvdEkhz",
        "colab_type": "code",
        "outputId": "1ab02872-e0bc-4739-9e4b-2fcb65b2a481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape\n",
        "# Y_train = to_categorical(Y_train,5)\n",
        "# y_test = to_categorical(y_test,5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkP1wOnxEnlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyDhDdDRE5NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Embedding, Flatten, GlobalAveragePooling1D\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrByIwfSSbsD",
        "colab_type": "code",
        "outputId": "c83ab22c-6674-4a0c-db04-084d0a746fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(128, 10,  activation='relu', input_shape=(2000,1)))\n",
        "model.add(Conv1D(128, 10, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(Conv1D(256, 10, activation='relu', input_shape=(2000,1)))\n",
        "model.add(Conv1D(256, 10, activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(rate = 0.50))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv0Vje_1E-oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adam(),\n",
        "#               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIW1tqKkFAe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiNvnHRSFCa4",
        "colab_type": "code",
        "outputId": "4b292a4e-316c-4999-b140-9071e3598719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=64,\n",
        "          epochs=50)\n",
        "# _, accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
        "# score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])\n",
        "\n",
        "# model.save('1106924_1dconv_reg.h5')\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "109242/109242 [==============================] - 80s 734us/step - loss: 0.4119 - acc: 0.8154 - f1_m: 0.4746 - precision_m: 0.5512 - recall_m: 0.4176\n",
            "Epoch 2/50\n",
            "109242/109242 [==============================] - 80s 733us/step - loss: 0.4119 - acc: 0.8154 - f1_m: 0.4744 - precision_m: 0.5507 - recall_m: 0.4176\n",
            "Epoch 3/50\n",
            "109242/109242 [==============================] - 80s 729us/step - loss: 0.4119 - acc: 0.8153 - f1_m: 0.4731 - precision_m: 0.5501 - recall_m: 0.4163\n",
            "Epoch 4/50\n",
            "109242/109242 [==============================] - 79s 722us/step - loss: 0.4119 - acc: 0.8153 - f1_m: 0.4720 - precision_m: 0.5498 - recall_m: 0.4151\n",
            "Epoch 5/50\n",
            "109242/109242 [==============================] - 79s 723us/step - loss: 0.4119 - acc: 0.8154 - f1_m: 0.4746 - precision_m: 0.5508 - recall_m: 0.4179\n",
            "Epoch 6/50\n",
            "109242/109242 [==============================] - 79s 723us/step - loss: 0.4120 - acc: 0.8153 - f1_m: 0.4716 - precision_m: 0.5500 - recall_m: 0.4148\n",
            "Epoch 7/50\n",
            "109242/109242 [==============================] - 79s 722us/step - loss: 0.4123 - acc: 0.8152 - f1_m: 0.4739 - precision_m: 0.5499 - recall_m: 0.4173\n",
            "Epoch 8/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4119 - acc: 0.8154 - f1_m: 0.4747 - precision_m: 0.5509 - recall_m: 0.4179\n",
            "Epoch 9/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4119 - acc: 0.8155 - f1_m: 0.4748 - precision_m: 0.5508 - recall_m: 0.4180\n",
            "Epoch 10/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4746 - precision_m: 0.5509 - recall_m: 0.4178\n",
            "Epoch 11/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4737 - precision_m: 0.5509 - recall_m: 0.4169\n",
            "Epoch 12/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4119 - acc: 0.8154 - f1_m: 0.4748 - precision_m: 0.5509 - recall_m: 0.4180\n",
            "Epoch 13/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4120 - acc: 0.8153 - f1_m: 0.4737 - precision_m: 0.5504 - recall_m: 0.4169\n",
            "Epoch 14/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4119 - acc: 0.8154 - f1_m: 0.4746 - precision_m: 0.5508 - recall_m: 0.4179\n",
            "Epoch 15/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4120 - acc: 0.8153 - f1_m: 0.4735 - precision_m: 0.5506 - recall_m: 0.4167\n",
            "Epoch 16/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4740 - precision_m: 0.5509 - recall_m: 0.4172\n",
            "Epoch 17/50\n",
            "109242/109242 [==============================] - 79s 726us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4743 - precision_m: 0.5508 - recall_m: 0.4176\n",
            "Epoch 18/50\n",
            "109242/109242 [==============================] - 79s 728us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4731 - precision_m: 0.5508 - recall_m: 0.4162\n",
            "Epoch 19/50\n",
            "109242/109242 [==============================] - 79s 727us/step - loss: 0.4119 - acc: 0.8154 - f1_m: 0.4742 - precision_m: 0.5502 - recall_m: 0.4176\n",
            "Epoch 20/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4749 - precision_m: 0.5509 - recall_m: 0.4182\n",
            "Epoch 21/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4744 - precision_m: 0.5505 - recall_m: 0.4180\n",
            "Epoch 22/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4738 - precision_m: 0.5506 - recall_m: 0.4173\n",
            "Epoch 23/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4121 - acc: 0.8154 - f1_m: 0.4750 - precision_m: 0.5505 - recall_m: 0.4186\n",
            "Epoch 24/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4745 - precision_m: 0.5506 - recall_m: 0.4180\n",
            "Epoch 25/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4746 - precision_m: 0.5504 - recall_m: 0.4182\n",
            "Epoch 26/50\n",
            "109242/109242 [==============================] - 80s 730us/step - loss: 0.4122 - acc: 0.8153 - f1_m: 0.4731 - precision_m: 0.5503 - recall_m: 0.4166\n",
            "Epoch 27/50\n",
            "109242/109242 [==============================] - 80s 733us/step - loss: 0.4120 - acc: 0.8152 - f1_m: 0.4738 - precision_m: 0.5500 - recall_m: 0.4174\n",
            "Epoch 28/50\n",
            "109242/109242 [==============================] - 80s 732us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4752 - precision_m: 0.5506 - recall_m: 0.4189\n",
            "Epoch 29/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4121 - acc: 0.8153 - f1_m: 0.4728 - precision_m: 0.5501 - recall_m: 0.4162\n",
            "Epoch 30/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4121 - acc: 0.8154 - f1_m: 0.4748 - precision_m: 0.5505 - recall_m: 0.4183\n",
            "Epoch 31/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4121 - acc: 0.8154 - f1_m: 0.4751 - precision_m: 0.5506 - recall_m: 0.4187\n",
            "Epoch 32/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4121 - acc: 0.8153 - f1_m: 0.4735 - precision_m: 0.5498 - recall_m: 0.4169\n",
            "Epoch 33/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4750 - precision_m: 0.5506 - recall_m: 0.4185\n",
            "Epoch 34/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4121 - acc: 0.8154 - f1_m: 0.4733 - precision_m: 0.5502 - recall_m: 0.4170\n",
            "Epoch 35/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4120 - acc: 0.8153 - f1_m: 0.4746 - precision_m: 0.5506 - recall_m: 0.4181\n",
            "Epoch 36/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4121 - acc: 0.8153 - f1_m: 0.4748 - precision_m: 0.5502 - recall_m: 0.4185\n",
            "Epoch 37/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4121 - acc: 0.8155 - f1_m: 0.4753 - precision_m: 0.5507 - recall_m: 0.4189\n",
            "Epoch 38/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4122 - acc: 0.8153 - f1_m: 0.4743 - precision_m: 0.5506 - recall_m: 0.4177\n",
            "Epoch 39/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4121 - acc: 0.8154 - f1_m: 0.4742 - precision_m: 0.5498 - recall_m: 0.4180\n",
            "Epoch 40/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4123 - acc: 0.8154 - f1_m: 0.4750 - precision_m: 0.5502 - recall_m: 0.4187\n",
            "Epoch 41/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4121 - acc: 0.8154 - f1_m: 0.4745 - precision_m: 0.5506 - recall_m: 0.4179\n",
            "Epoch 42/50\n",
            "109242/109242 [==============================] - 79s 719us/step - loss: 0.4121 - acc: 0.8154 - f1_m: 0.4746 - precision_m: 0.5507 - recall_m: 0.4180\n",
            "Epoch 43/50\n",
            "109242/109242 [==============================] - 79s 719us/step - loss: 0.4120 - acc: 0.8153 - f1_m: 0.4749 - precision_m: 0.5507 - recall_m: 0.4183\n",
            "Epoch 44/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4750 - precision_m: 0.5504 - recall_m: 0.4187\n",
            "Epoch 45/50\n",
            "109242/109242 [==============================] - 79s 720us/step - loss: 0.4126 - acc: 0.8153 - f1_m: 0.4738 - precision_m: 0.5505 - recall_m: 0.4171\n",
            "Epoch 46/50\n",
            "109242/109242 [==============================] - 79s 721us/step - loss: 0.4122 - acc: 0.8153 - f1_m: 0.4746 - precision_m: 0.5504 - recall_m: 0.4182\n",
            "Epoch 47/50\n",
            "109242/109242 [==============================] - 80s 729us/step - loss: 0.4121 - acc: 0.8153 - f1_m: 0.4740 - precision_m: 0.5500 - recall_m: 0.4176\n",
            "Epoch 48/50\n",
            "109242/109242 [==============================] - 80s 730us/step - loss: 0.4120 - acc: 0.8153 - f1_m: 0.4742 - precision_m: 0.5510 - recall_m: 0.4175\n",
            "Epoch 49/50\n",
            "109242/109242 [==============================] - 80s 729us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4750 - precision_m: 0.5507 - recall_m: 0.4185\n",
            "Epoch 50/50\n",
            "109242/109242 [==============================] - 79s 722us/step - loss: 0.4120 - acc: 0.8154 - f1_m: 0.4744 - precision_m: 0.5508 - recall_m: 0.4179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8306ce7dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnF7wZVDrpoy",
        "colab_type": "code",
        "outputId": "cce43912-7f52-4396-9fe6-f5a3a643b006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/1106924_1dconv_reg.h5',custom_objects = {'f1_m': f1_m,  'precision_m': precision_m, 'recall_m' : recall_m})\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 1991, 128)         1408      \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1982, 128)         163968    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 660, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 651, 256)          327936    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 642, 256)          655616    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 1,150,213\n",
            "Trainable params: 1,150,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAzzABZvKe_o",
        "colab_type": "code",
        "outputId": "9a32b6cc-4daf-4b07-e72f-9df416be718b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "print('loss:\\t', loss)\n",
        "print('accuracy:\\t', accuracy)\n",
        "print('f1_score:\\t', f1_score)\n",
        "print('precision:\\t', precision)\n",
        "print('recall:\\t', recall)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:\t 0.41282419631775413\n",
            "accuracy:\t 0.8153872535863147\n",
            "f1_score:\t 0.4737326902990599\n",
            "precision:\t 0.5508104965216153\n",
            "recall:\t 0.41736084411978297\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}